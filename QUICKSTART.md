# üöÄ Guide de D√©marrage Rapide - BRVM Data API

## ‚ö° D√©marrage en 5 minutes

### Option 1: Docker Compose (Recommand√©)

```bash
# 1. Cloner et entrer dans le projet
git clone <votre-repo>
cd brvm-api

# 2. Configuration
cp .env.example .env
# √âditer .env si n√©cessaire

# 3. D√©marrer
docker-compose up -d

# 4. V√©rifier
curl http://localhost:8000/health
```

**C'est tout ! L'API est accessible sur http://localhost:8000/docs**

### Option 2: Local (Sans Docker)

```bash
# 1. Configuration
cp .env.example .env
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt

# 2. Base de donn√©es (MySQL doit √™tre install√©)
mysql -u root -p < init.sql

# 3. Lancer
python -m uvicorn app.main:app --reload
```

## üìã Checklist apr√®s installation

- [ ] L'API r√©pond sur http://localhost:8000
- [ ] Swagger accessible sur http://localhost:8000/docs
- [ ] Health check OK: `curl http://localhost:8000/health`
- [ ] MySQL connect√© (voir logs)
- [ ] Scheduler actif (voir `/scheduler/status`)

## üéØ Premiers tests

### 1. V√©rifier le statut
```bash
curl http://localhost:8000/health
```

### 2. D√©clencher un scraping manuel
```bash
curl -X POST http://localhost:8000/scheduler/trigger/scrape_brvm
```

### 3. R√©cup√©rer les actions
```bash
curl http://localhost:8000/api/actions
```

### 4. Enregistrer un webhook
```bash
curl -X POST http://localhost:8000/api/webhooks/register \
  -H "Content-Type: application/json" \
  -d '{"url": "https://webhook.site/unique-id", "description": "Test"}'
```

### 5. Tester les webhooks
```bash
curl -X POST http://localhost:8000/api/webhooks/test-push
```

## üìä Acc√®s aux services

| Service | URL | Description |
|---------|-----|-------------|
| API | http://localhost:8000 | Endpoint principal |
| Swagger UI | http://localhost:8000/docs | Documentation interactive |
| ReDoc | http://localhost:8000/redoc | Documentation alternative |
| Health Check | http://localhost:8000/health | Statut de l'application |
| Scheduler | http://localhost:8000/scheduler/status | √âtat des t√¢ches |

## üîß Commandes utiles

### Avec Docker
```bash
# Voir les logs en temps r√©el
docker-compose logs -f api

# Red√©marrer l'API
docker-compose restart api

# Arr√™ter tout
docker-compose down

# Arr√™ter et supprimer les donn√©es
docker-compose down -v
```

### Avec Makefile
```bash
make up          # D√©marrer
make logs        # Voir les logs
make down        # Arr√™ter
make test        # Lancer les tests
make clean       # Nettoyer
```

## üêõ D√©pannage rapide

### L'API ne d√©marre pas
```bash
# V√©rifier les logs
docker-compose logs api

# V√©rifier MySQL
docker-compose logs mysql

# Red√©marrer proprement
docker-compose down
docker-compose up -d
```

### Erreur de connexion MySQL
```bash
# V√©rifier que MySQL est d√©marr√©
docker-compose ps mysql

# Recr√©er la base
docker-compose down -v
docker-compose up -d
```

### Le scraping ne fonctionne pas
```bash
# Tester manuellement l'URL
curl https://www.brvm.org/fr/cours-actions/0

# V√©rifier les logs du scraper
docker-compose logs api | grep scraping

# D√©clencher manuellement
curl -X POST http://localhost:8000/scheduler/trigger/scrape_brvm
```

### PDF non t√©l√©charg√©
```bash
# V√©rifier l'URL du jour
date +%Y%m%d

# Tester manuellement
curl -I https://www.brvm.org/sites/default/files/boc_$(date +%Y%m%d)_2.pdf

# D√©clencher manuellement
curl -X POST http://localhost:8000/scheduler/trigger/extract_pdf_12h
```

## üìù Configuration importante

### Variables .env essentielles
```bash
# Base de donn√©es
DATABASE_URL=mysql+pymysql://brvm_user:brvm_password@localhost:3306/brvm_db

# Scraping
SCRAPER_INTERVAL_MINUTES=30

# Timezone (important pour le scheduler)
TIMEZONE=Africa/Abidjan
```

## üéì Exemples d'utilisation

### R√©cup√©rer toutes les actions
```bash
curl http://localhost:8000/api/actions
```

### Filtrer par symbole
```bash
curl "http://localhost:8000/api/actions?symbole=BICC"
```

### Top 10 actions par volume
```bash
curl "http://localhost:8000/api/actions/top/volume?limit=10"
```

### Dernier indicateur du march√©
```bash
curl http://localhost:8000/api/indicateurs/latest
```

### Historique d'une action
```bash
curl http://localhost:8000/api/historique/BICC
```

### Indicateurs sur une p√©riode
```bash
curl "http://localhost:8000/api/indicateurs/range?start_date=2025-10-01&end_date=2025-10-31"
```

## üîî Configuration des Webhooks

### 1. Cr√©er un webhook de test sur webhook.site
Allez sur https://webhook.site et copiez votre URL unique

### 2. Enregistrer le webhook
```bash
curl -X POST http://localhost:8000/api/webhooks/register \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://webhook.site/VOTRE-ID-UNIQUE",
    "description": "Webhook de test"
  }'
```

### 3. Tester
```bash
curl -X POST http://localhost:8000/api/webhooks/test-push
```

V√©rifiez sur webhook.site que vous avez re√ßu le payload !

## üì± Int√©gration avec d'autres services

### Zapier
1. Cr√©er un Zap avec "Webhooks by Zapier"
2. Copier l'URL du webhook
3. L'enregistrer dans l'API

### Make (Integromat)
1. Cr√©er un sc√©nario avec "Webhooks"
2. Copier l'URL du webhook
3. L'enregistrer dans l'API

### Discord
1. Cr√©er un webhook Discord dans les param√®tres du canal
2. Enregistrer l'URL dans l'API
3. Adapter le payload si n√©cessaire

## üöÄ D√©ploiement sur Render

### 1. Pr√©parer le repository
```bash
git init
git add .
git commit -m "Initial commit"
git push origin main
```

### 2. Sur Render
1. Cr√©er un nouveau "Web Service"
2. Connecter votre repository GitHub
3. Configuration:
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`
   - **Environment**: Python 3
4. Ajouter une base MySQL depuis Render
5. D√©finir les variables d'environnement

### 3. Variables d'environnement Render
```
DATABASE_URL=<Render Database URL>
DEBUG=false
LOG_LEVEL=INFO
TIMEZONE=Africa/Abidjan
SCRAPER_INTERVAL_MINUTES=30
```

### 4. Tester
```bash
curl https://votre-app.onrender.com/health
```

## üìä Monitoring et Maintenance

### V√©rifier les logs
```bash
# Derni√®res 100 lignes
docker-compose logs --tail=100 api

# Suivre en temps r√©el
docker-compose logs -f api

# Filtrer par niveau
docker-compose logs api | grep ERROR
```

### V√©rifier l'espace disque
```bash
# Voir les PDF t√©l√©charg√©s
ls -lh downloads/

# Voir les logs
ls -lh logs/

# Nettoyer les vieux PDF (garder 7 jours)
find downloads/ -name "*.pdf" -mtime +7 -delete
```

### Statistiques de la base
```bash
# Nombre d'actions
docker-compose exec mysql mysql -u root -p brvm_db -e "SELECT COUNT(*) FROM actions;"

# Nombre d'indicateurs
docker-compose exec mysql mysql -u root -p brvm_db -e "SELECT COUNT(*) FROM indicateurs_marche;"

# Taille de la base
docker-compose exec mysql mysql -u root -p brvm_db -e "SELECT table_name, ROUND(((data_length + index_length) / 1024 / 1024), 2) AS 'Size (MB)' FROM information_schema.TABLES WHERE table_schema = 'brvm_db';"
```

## üîí S√©curit√©

### Checklist de production
- [ ] Changer tous les mots de passe par d√©faut
- [ ] Utiliser HTTPS (certificat SSL)
- [ ] Limiter les origines CORS
- [ ] Activer l'authentification API (√† impl√©menter)
- [ ] Restreindre l'acc√®s √† la base de donn√©es
- [ ] Surveiller les logs d'erreur
- [ ] Mettre en place des alertes

### Recommandations
1. **Ne jamais committer le fichier .env**
2. **Utiliser des secrets managers** (Render Secrets, AWS Secrets Manager)
3. **Limiter les webhooks** √† des domaines de confiance
4. **Monitorer les requ√™tes** pour d√©tecter les abus

## üìà Optimisations

### Pour de meilleures performances

1. **Ajuster le pool de connexions**
```env
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=40
```

2. **Augmenter la fr√©quence de scraping**
```env
SCRAPER_INTERVAL_MINUTES=15
```

3. **Ajouter un cache Redis** (√† impl√©menter)

4. **Utiliser Gunicorn** pour le mode production
```bash
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

## üéØ Prochaines √©tapes

1. ‚úÖ V√©rifier que tout fonctionne
2. üìù Personnaliser les configurations
3. üîî Configurer vos webhooks
4. üöÄ D√©ployer en production
5. üìä Monitorer les performances
6. üîß Ajuster selon vos besoins

## üí° Astuces

### Utiliser httpie pour des requ√™tes plus lisibles
```bash
# Installer httpie
pip install httpie

# Utiliser
http GET http://localhost:8000/api/actions
http POST http://localhost:8000/api/webhooks/register url=https://example.com/webhook
```

### Cr√©er des alias
```bash
# Ajouter dans ~/.bashrc ou ~/.zshrc
alias brvm-start='docker-compose up -d'
alias brvm-stop='docker-compose down'
alias brvm-logs='docker-compose logs -f api'
alias brvm-scrape='curl -X POST http://localhost:8000/scheduler/trigger/scrape_brvm'
```

### Surveiller en continu
```bash
# Installer watch
# Linux: apt-get install watch
# Mac: brew install watch

# Surveiller le health check
watch -n 5 'curl -s http://localhost:8000/health | python -m json.tool'
```

## üÜò Support

### Probl√®me non r√©solu ?
1. V√©rifier les logs: `docker-compose logs api`
2. V√©rifier le README.md complet
3. Consulter la documentation Swagger: http://localhost:8000/docs
4. Ouvrir une issue sur GitHub

### Ressources utiles
- Documentation FastAPI: https://fastapi.tiangolo.com
- Documentation SQLAlchemy: https://docs.sqlalchemy.org
- Documentation APScheduler: https://apscheduler.readthedocs.io
- Site BRVM: https://www.brvm.org

---

**üéâ F√©licitations ! Votre API BRVM est op√©rationnelle !**

Pour toute question, consultez le README.md complet ou les logs de l'application.
